{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPR Bayesian Personalized Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ThetaLog.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load các thư viện cần thiết\n",
    "import os\n",
    "import math\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "from scipy.sparse import csr_matrix, dok_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "\n",
    "np.random.seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = './MINDlarge_test/behaviors.tsv'\n",
    "train_path = './MINDlarge_train/behaviors.tsv'\n",
    "\n",
    "output_test_path = './datafile/large_test.csv'\n",
    "output_train_path = './datafile/large_train.csv'\n",
    "\n",
    "result_test_file = 'large_test'\n",
    "result_train_file = 'large_train'\n",
    "\n",
    "user_min = 150\n",
    "item_min = 150\n",
    "\n",
    "test_ratio = 0.5\n",
    "\n",
    "alpha=0.001\n",
    "lamb=0.02\n",
    "k=60\n",
    "n_iters=600000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_behaviors(path):\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        sep = \"\\t\",\n",
    "        names = [\"id\", \"user_id\", \"time\", \"history\", \"impressions\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def write_file(df, path):\n",
    "    t_start = time()\n",
    "    print(\"Processing\", path)\n",
    "    with open(path, \"w\") as file:\n",
    "        for i, row in df.iterrows():\n",
    "            for new_id in str(row.history).split(' '):\n",
    "                if row.user_id[1:].isnumeric() and new_id[1:].isnumeric():\n",
    "                    file.write(row.user_id[1:] + \",\" + new_id[1:] + \"\\n\")\n",
    "\n",
    "    t_end = time()\n",
    "    print(\"Processed in: {:.2f} Seconds\".format(t_end - t_start))\n",
    "\n",
    "def write_data_file(test_path, train_path, output_test_path, output_train_path):\n",
    "    test_df, train_df = load_behaviors(test_path), load_behaviors(train_path)\n",
    "\n",
    "    write_file(test_df, output_test_path)\n",
    "    write_file(train_df, output_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_data_file(test_path, train_path, output_test_path, output_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        header=None,\n",
    "        names=['user_id', 'item_id']\n",
    "    )\n",
    "    df.reindex(columns = ['user_id', 'item_id'])\n",
    "    return df.reset_index(drop = True)\n",
    "\n",
    "def load_data(test_path, train_path):\n",
    "#     test_df, train_df = load_file(test_path), load_file(train_path)\n",
    "    \n",
    "#     return test_df, train_df\n",
    "    return load_file(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data(output_test_path, output_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, user_min, item_min):\n",
    "    if df is None:\n",
    "        return\n",
    "\n",
    "    t_start = time()\n",
    "\n",
    "    user_counts = df.groupby(\"user_id\").size()\n",
    "    user_subset = np.in1d(\n",
    "        df.user_id, user_counts[user_counts >= item_min].index\n",
    "    )\n",
    "\n",
    "    filter_df = df[user_subset].reset_index(drop=True)\n",
    "\n",
    "    # find items with 10 or more users\n",
    "    item_counts = filter_df.groupby(\"item_id\").size()\n",
    "    item_subset = np.in1d(\n",
    "        filter_df.item_id, item_counts[item_counts >= user_min].index\n",
    "    )\n",
    "\n",
    "    filter_df = filter_df[item_subset].reset_index(drop=True)\n",
    "\n",
    "    user_counts = filter_df.groupby(\"user_id\").size()\n",
    "    user_subset = np.in1d(filter_df.user_id, user_counts[user_counts >= item_min].index)\n",
    "\n",
    "    filter_df = filter_df[user_subset].reset_index(drop=True)\n",
    "\n",
    "    t_end = time()\n",
    "\n",
    "    assert (filter_df.groupby(\"user_id\").size() < 5).sum() == 0\n",
    "    assert (filter_df.groupby(\"item_id\").size() < 5).sum() == 0\n",
    "\n",
    "    print(filter_df.nunique())\n",
    "    print(filter_df.shape)\n",
    "    print(\"{:.2f} Seconds\".format(t_end - t_start))\n",
    "\n",
    "    return filter_df\n",
    "\n",
    "def reset_df(df):\n",
    "    item_enc = LabelEncoder()\n",
    "    df[\"item_id\"] = item_enc.fit_transform(df[\"item_id\"])\n",
    "\n",
    "    user_enc = LabelEncoder()\n",
    "    df[\"user_id\"] = user_enc.fit_transform(df[\"user_id\"])\n",
    "\n",
    "    assert df.user_id.min() == 0\n",
    "    assert df.item_id.min() == 0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id    99387\n",
      "item_id    16261\n",
      "dtype: int64\n",
      "(54080634, 2)\n",
      "17.86 Seconds\n"
     ]
    }
   ],
   "source": [
    "filtered_train_df = reset_df(filter_df(train_df, user_min, item_min))\n",
    "# filtered_test_df = reset_df(filter_df(test_df, user_min, item_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bpr_mat(dataframe, threshold = 3):\n",
    "    \"\"\"\n",
    "    Chuyển đổi DataFrame MovieLens 100K ban đầu sang ma trận BPR\n",
    "    Mỗi dòng là Users\n",
    "    Mỗi cột là Item\n",
    "    Định dạng ma trận thưa\n",
    "\n",
    "    :param dataframe: pandas df movielens 100K\n",
    "    :return bpr_mat: np.array - ma trận thưa bpr\n",
    "    \"\"\"\n",
    "    tempdf = dataframe.copy()\n",
    "    tempdf['ratings'] = 5\n",
    "    tempdf['positive'] = tempdf['ratings'].apply(func=lambda x: 0 if x < threshold else 1)\n",
    "\n",
    "    # Vì tập dữ liệu này đánh index từ 1 nên chuyển sang kiểu category\n",
    "    # để tránh việc chúng ta có ma trận\n",
    "    tempdf['user_id'] = tempdf['user_id'].astype('category')\n",
    "    tempdf['item_id'] = tempdf['item_id'].astype('category')\n",
    "\n",
    "    bpr_mat = csr_matrix((tempdf['positive'],\n",
    "                          (tempdf['user_id'].cat.codes,\n",
    "                           tempdf['item_id'].cat.codes)))\n",
    "    bpr_mat.eliminate_zeros()\n",
    "    del tempdf\n",
    "    return bpr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_train = convert_to_bpr_mat(filtered_train_df)\n",
    "# bpr_test = convert_to_bpr_mat(filtered_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99387, 16261)\n"
     ]
    }
   ],
   "source": [
    "print(bpr_train.shape)\n",
    "# print(bpr_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_train_test(bpr_mat, test_ratio = 0.2, verbose=True):\n",
    "    \"\"\"\n",
    "    Chia tập dữ liệu ra thành tập train & tập test\n",
    "\n",
    "    :param bpr_mat: ma trận bpr\n",
    "    :param test_ratio: float - tỉ lệ test set\n",
    "\n",
    "    :return train: ma trận bpr train\n",
    "    :return test: ma trận bpr test\n",
    "    \"\"\"\n",
    "    # Số lượng người dùng\n",
    "    n_users = bpr_mat.shape[0]\n",
    "    # Dùng ma trận thưa Dictionary Of Keys tối ưu hơn cho công đoạn này\n",
    "    train = bpr_mat.copy().todok()\n",
    "    test = dok_matrix(train.shape) # Lưu ý hiện tại test là ma trận 0\n",
    "\n",
    "    # với mỗi người dùng u\n",
    "    # chia số trường hợp nên khuyến nghị với tỉ lệ test_ratio đươc cho\n",
    "    # phần nào thuộc về test\n",
    "    for u in range(n_users):\n",
    "        split_index = bpr_mat[u].indices\n",
    "        # đếm số trường hợp nên khuyến nghị\n",
    "        count_positive = split_index.shape[0]\n",
    "        n_splits = max(min(math.ceil(test_ratio * count_positive), count_positive - 1), 1)\n",
    "        test_index = np.random.choice(split_index, size=n_splits, replace=False)\n",
    "        # Xem như dữ liệu chưa biết trong tập train\n",
    "        train[u, test_index] = 0\n",
    "        # Xem như dữ liệu nhìn thấy trong tập test\n",
    "        test[u, test_index] = 1\n",
    "\n",
    "    train, test = train.tocsr(), test.tocsr()\n",
    "\n",
    "    # Nếu cần in thông tin ra ngoài\n",
    "    if verbose:\n",
    "        print('BPR matrix with %d stored elements' % bpr_mat.nnz)\n",
    "        print('Train matrix with %d stored elements' % train.nnz)\n",
    "        print('Test matrix with %d stored elements' % test.nnz)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPR matrix with 5793131 stored elements\n",
      "Train matrix with 2871848 stored elements\n",
      "Test matrix with 2921283 stored elements\n"
     ]
    }
   ],
   "source": [
    "bpr_train_train, bpr_train_test = split_to_train_test(bpr_train, test_ratio=test_ratio, verbose=True)\n",
    "# bpr_test_train, bpr_test_test = split_to_train_test(bpr_test, test_ratio=test_ratio, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bpr(W, H, user=None):\n",
    "    \"\"\"\n",
    "    Hàm trả về X_hat\n",
    "\n",
    "    :param W: ma trận W từ MF\n",
    "    :param H: ma trận H từ MF\n",
    "    :param user: người dùng (nếu None mặt định trả về tất cả)\n",
    "\n",
    "    :return predict_scores: điểm dự đoán từ BPR MF\n",
    "    \"\"\"\n",
    "    if user is None:\n",
    "        return W @ H.T\n",
    "    else:\n",
    "        return W[user] @ H.T\n",
    "\n",
    "def recommend_bpr(bpr_matrix, predict_score, user, n_rmd_items=None):\n",
    "    \"\"\"\n",
    "    Dự đoán những sản phẩm mà người dùng muốn mua\n",
    "    Những sản phẩm nào đã thích rồi thì không trả về nữa\n",
    "    Trả về index theo bpr_matrix (đánh từ 0)\n",
    "\n",
    "    :param bpr_matrix: ma trận bpr hiện tại\n",
    "    :param predict_score: điểm dự đoán các item\n",
    "    :param user: số thứ tự người dùng của predict score\n",
    "    :param n_rmd_items: số lượng sản phẩm trả về, mặc định tất cả\n",
    "\n",
    "    :return rmd_items: danh sách các sản phẩm khuyến nghị\n",
    "    \"\"\"\n",
    "    # Số lượng sản phẩm\n",
    "    n_items = bpr_matrix.shape[1]\n",
    "    # những sản phẩm đã thích rồi\n",
    "    liked_items = bpr_matrix[user].indices\n",
    "    scores = predict_score.copy()\n",
    "\n",
    "    # index ban đầu khi chưa sắp xếp\n",
    "    sort_index = np.arange(0, n_items)\n",
    "\n",
    "    # Xóa các sản phẩm đã mua\n",
    "    sort_index = np.delete(sort_index, liked_items)\n",
    "    scores = np.delete(scores, liked_items)\n",
    "\n",
    "    # sắp xếp và trả về theo số thứ tự của score\n",
    "    arg_sort = np.argsort(-scores)\n",
    "\n",
    "    # dùng sort_index để lấy số thứ tự ban đầu\n",
    "    rmd_items = sort_index[arg_sort]\n",
    "\n",
    "    if len(rmd_items) >= n_rmd_items and n_rmd_items is not None:\n",
    "        rmd_items = rmd_items[: n_rmd_items]\n",
    "    return rmd_items\n",
    "\n",
    "def auc_score(predict_mat, bpr_mat):\n",
    "    \"\"\"\n",
    "    Tính Area under the ROC curve (AUC)\n",
    "    cho bài toán hệ khuyến nghị\n",
    "\n",
    "    :param predict_mat: ma trận dữ đoán bpr mf\n",
    "    :param bpr_mat: ma trận train hoặc test\n",
    "    :return auc: area under the roc curve\n",
    "    \"\"\"\n",
    "    auc = 0.0\n",
    "    n_users, n_items = bpr_mat.shape\n",
    "\n",
    "    # u và row tương ứng user và bp\n",
    "    for u in range(n_users):\n",
    "        y_pred = predict_mat[u]\n",
    "        y_true = np.zeros(n_items)\n",
    "        y_true[bpr_mat[u].indices] = 1\n",
    "        try:\n",
    "            auc += roc_auc_score(y_true, y_pred)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    auc /= n_users\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_bpr_mf_sgd(bpr_mat, pos, neg, W = None, H = None, alpha=0.01, lamb=0.01, k=12, n_iters=10000):\n",
    "    \"\"\"\n",
    "    Thuật toán học BPR MF SGD (một điểm dữ liệu duy nhất)\n",
    "\n",
    "    :param bpr_mat: ma trận bpr\n",
    "    :param alpha: hệ số learning rate\n",
    "    :param lamb: hệ số lambda của bình thường hóa regularization\n",
    "    :param k: số lượng latent factor trong bài toán MF\n",
    "    :param n_iters: số vòng lặp\n",
    "\n",
    "    :return W: ma trận W\n",
    "    :return H: ma trận H\n",
    "    \"\"\"\n",
    "    n_users, n_items = bpr_mat.shape\n",
    "    # Khởi tạo ma trận W và ma trận H\n",
    "    if W is None:\n",
    "        W = np.ones(shape=(n_users, k))\n",
    "    if H is None:\n",
    "        H = np.ones(shape=(n_items, k))\n",
    "\n",
    "    # lặp\n",
    "    for _ in range(n_iters):\n",
    "        # ngẫu nghiên 3 bộ (u,i,j) từ D_S\n",
    "        u = np.random.randint(0, n_users)\n",
    "        if len(pos[u]) == 0:\n",
    "            continue\n",
    "        i = pos[u][np.random.randint(0, len(pos[u]))]\n",
    "        j = neg[u][np.random.randint(0, len(neg[u]))]\n",
    "\n",
    "        # Tính xuij\n",
    "        xui = (W[u] * H[i]).sum()\n",
    "        xuj = (W[u] * H[j]).sum()\n",
    "        xuij = xui - xuj\n",
    "\n",
    "        # mũ tự nhiên e của xuij\n",
    "        exp_xuij = np.exp(xuij)\n",
    "\n",
    "        # sgd cho tham số Theta (W và H)\n",
    "        W[u] = W[u] + alpha * ( exp_xuij / (1+exp_xuij) * (H[i] - H[j]) + lamb * W[u])\n",
    "        H[i] = H[i] + alpha * ( exp_xuij / (1+exp_xuij) * W[u] + lamb * H[i])\n",
    "        H[j] = H[j] + alpha * ( exp_xuij / (1+exp_xuij) * (-W[u]) + lamb * H[j])\n",
    "    return W, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_train, H_train = None, None\n",
    "\n",
    "# Tập các sản phẩm nên khuyến nghị\n",
    "pos = np.split(bpr_train_train.indices, bpr_train_train.indptr)[1:-1]\n",
    "# Tập các sản phẩm không nên khuyến nghị\n",
    "neg = [np.setdiff1d(np.arange(0, bpr_train_train.shape[1], 1), e) for e in pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Train: 0.852319\n",
      "Train-Test: 0.851468\n"
     ]
    }
   ],
   "source": [
    "W_train, H_train = learn_bpr_mf_sgd(\n",
    "    bpr_train_train,\n",
    "    pos,\n",
    "    neg,\n",
    "    W = W_train,\n",
    "    H = H_train,\n",
    "    alpha=alpha,\n",
    "    lamb=lamb,\n",
    "    k=k,\n",
    "    n_iters=n_iters\n",
    ")\n",
    "\n",
    "pred_train = predict_bpr(W_train, H_train)\n",
    "\n",
    "train_train = auc_score(pred_train, bpr_train_train)\n",
    "train_test = auc_score(pred_train, bpr_train_test)\n",
    "print('Train-Train: %f' % train_train)\n",
    "print('Train-Test: %f' % train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = os.path.join('./result', datetime.now().strftime(\"%d-%m-%Y %H-%M\"))\n",
    "\n",
    "pathlib.Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(output_folder, result_train_file + '_W.npy'), W_train)\n",
    "np.save(os.path.join(output_folder, result_train_file + '_H.npy'), H_train)\n",
    "\n",
    "with open(os.path.join(output_folder, result_train_file + '.txt'), 'w') as file:\n",
    "    file.write('user min: %i' % user_min + \"\\n\")\n",
    "    file.write('item min: %i' % item_min + \"\\n\")\n",
    "    file.write('test ratio: %f' % test_ratio + \"\\n\")\n",
    "    file.write('alpha: %f' % alpha + \"\\n\")\n",
    "    file.write('lambda: %f' % lamb + \"\\n\")\n",
    "    file.write('k: %i' % k + \"\\n\")\n",
    "    file.write('n iters: %i' % n_iters + \"\\n\")\n",
    "    file.write('Train-Train: %f' % train_train + \"\\n\")\n",
    "    file.write('Train-Test: %f' % train_test + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bpr_test_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m W_test, H_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Tập các sản phẩm nên khuyến nghị\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m pos \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msplit(\u001b[43mbpr_test_train\u001b[49m\u001b[38;5;241m.\u001b[39mindices, bpr_test_train\u001b[38;5;241m.\u001b[39mindptr)[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Tập các sản phẩm không nên khuyến nghị    file.write('training shape: ' + str())\u001b[39;00m\n\u001b[1;32m      6\u001b[0m neg \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39msetdiff1d(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, bpr_test_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m), e) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m pos]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bpr_test_train' is not defined"
     ]
    }
   ],
   "source": [
    "W_test, H_test = None, None\n",
    "# Tập các sản phẩm nên khuyến nghị\n",
    "pos = np.split(bpr_test_train.indices, bpr_test_train.indptr)[1:-1]\n",
    "# Tập các sản phẩm không nên khuyến nghị    file.write('training shape: ' + str())\n",
    "\n",
    "neg = [np.setdiff1d(np.arange(0, bpr_test_train.shape[1], 1), e) for e in pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_test, H_test = learn_bpr_mf_sgd(\n",
    "    bpr_test_train,\n",
    "    pos,\n",
    "    neg,\n",
    "    W = W_test,\n",
    "    H = H_test,\n",
    "    alpha=alpha,\n",
    "    lamb=lamb,\n",
    "    k=k,\n",
    "    n_iters=n_iters\n",
    ")\n",
    "\n",
    "pred_test = predict_bpr(W_test, H_test)\n",
    "\n",
    "test_train = auc_score(pred_test, bpr_test_train)\n",
    "test_test = auc_score(pred_test, bpr_test_test)\n",
    "print('Test-Train: %f' % test_train)\n",
    "print('Test-Test: %f' % test_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = os.path.join('./result', datetime.now().strftime(\"%d-%m-%Y %H-%M\"))\n",
    "\n",
    "pathlib.Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(output_folder, result_test_file + '_W.npy'), W_test)\n",
    "np.save(os.path.join(output_folder, result_test_file + '_H.npy'), H_test)\n",
    "\n",
    "with open(os.path.join(output_folder, result_test_file + '.txt'), 'w') as file:\n",
    "    file.write('user min: %i' % user_min + \"\\n\")\n",
    "    file.write('item min: %i' % item_min + \"\\n\")\n",
    "    file.write('test ratio: %f' % test_ratio + \"\\n\")\n",
    "    file.write('alpha: %f' % alpha + \"\\n\")\n",
    "    file.write('lambda: %f' % lamb + \"\\n\")\n",
    "    file.write('k: %i' % k + \"\\n\")\n",
    "    file.write('n iters: %i' % n_iters + \"\\n\")\n",
    "    file.write('Test-Train: %f' % test_train + \"\\n\")\n",
    "    file.write('Test-Test: %f' % test_test + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 300\n",
    "n_rmd_items = 5\n",
    "score = predict_bpr(W_test, H_test, u)\n",
    "rmd_items = recommend_bpr(bpr_test_train, score, u, n_rmd_items)\n",
    "print(rmd_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tham khảo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner and Lars Schmidt-Thieme. BPR: Bayesian Personalized Ranking from Implicit Feedback. \n",
    "02. Weike Panand, Li Chen. GBPR: Group Preference Based Bayesian Personalized Ranking for One-Class Collaborative Filtering. Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence. https://www.aaai.org/ocs/index.php/IJCAI/IJCAI13/paper/viewFile/6316/7124\n",
    "03. Michael D. Ekstrand, Joseph A Konstan. Personalized Ranking (with Daniel Kluver). Matrix Factorization and Advanced Techniques - University of Minnesota. https://www.coursera.org/lecture/matrix-factorization/personalized-ranking-with-daniel-kluver-s3XJo\n",
    "04. Kim Falk. Practical Recommender Systems. Manning Publications.\n",
    "05. Ethen (MingYu) Liu. Bayesian Personalized Ranking. http://ethen8181.github.io/machine-learning/recsys/4_bpr.html\n",
    "06. Alfredo Láinez Rodrigo, Luke de Oliveira. Distributed Bayesian Personalized Ranking in Spark. https://stanford.edu/~rezab/classes/cme323/S16/projects_reports/rodrigo_oliveira.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
