{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPR Bayesian Personalized Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ThetaLog.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load các thư viện cần thiết\n",
    "import os\n",
    "import math\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "from scipy.sparse import csr_matrix, dok_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "np.random.seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './MINDsmall_train/behaviors.tsv'\n",
    "\n",
    "output_train_path = './datafile/small_train.csv'\n",
    "\n",
    "result_train_file = 'small_train'\n",
    "\n",
    "user_min = 30\n",
    "item_min = 30\n",
    "\n",
    "test_ratio = 0.9\n",
    "\n",
    "alpha=0.001\n",
    "lamb=0.02\n",
    "k=60\n",
    "n_iters=300000\n",
    "initial_value = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Similarity:\n",
    "    def __init__(self, type='train'):\n",
    "        self.path = f'./MINDsmall_{type}/news.tsv'\n",
    "        self.df = pd.read_csv(self.path, sep='\\t', names=['News_ID', \"Category\", \"SubCategory\", \"Title\", \"Abstract\", \"URL\", \"CreatedAt\", \"Body\"], skiprows = 1)\n",
    "        self.df['title_body'] = self.df[['Title', 'Body']].apply(\n",
    "            lambda x: ' '.join(x.dropna().astype(str)),\n",
    "            axis=1\n",
    "        )\n",
    "        self.df.drop(columns=[\"Category\", \"SubCategory\", \"Title\", \"Abstract\", \"URL\", 'CreatedAt'])\n",
    "        self.calc_tf_idf()\n",
    "        self.create_news_index()\n",
    "\n",
    "    def create_news_index(self):\n",
    "        self.mark = dict()\n",
    "        for id, item in self.df['News_ID'].iteritems():\n",
    "            self.mark[int(item[1:])] = id\n",
    "\n",
    "    def calc_tf_idf(self):\n",
    "        vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        corpus = self.df['title_body'].dropna()\n",
    "        self.tf_idf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    def similarity(self, item_i, item_j):\n",
    "        x = self.mark[item_i]\n",
    "        y = self.mark[item_j]\n",
    "        return cosine_similarity(self.tf_idf_matrix[x], self.tf_idf_matrix[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_behaviors(path):\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        sep = \"\\t\",\n",
    "        names = [\"id\", \"user_id\", \"time\", \"history\", \"impressions\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def write_file(df, path):\n",
    "    t_start = time()\n",
    "    print(\"Processing\", path)\n",
    "    with open(path, \"w\") as file:\n",
    "        for i, row in df.iterrows():\n",
    "            for new_id in str(row.history).split(' '):\n",
    "                if row.user_id[1:].isnumeric() and new_id[1:].isnumeric():\n",
    "                    file.write(row.user_id[1:] + \",\" + new_id[1:] + \"\\n\")\n",
    "\n",
    "    t_end = time()\n",
    "    print(\"Processed in: {:.2f} Seconds\".format(t_end - t_start))\n",
    "\n",
    "def write_data_file(train_path, output_train_path):\n",
    "    train_df = load_behaviors(train_path)\n",
    "\n",
    "    write_file(train_df, output_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_data_file(train_path, output_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        header=None,\n",
    "        names=['user_id', 'item_id']\n",
    "    )\n",
    "    df.reindex(columns = ['user_id', 'item_id'])\n",
    "    return df.reset_index(drop = True)\n",
    "\n",
    "def load_data(train_path):\n",
    "    train_df = load_file(train_path)\n",
    "    \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data(output_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, user_min, item_min):\n",
    "    if df is None:\n",
    "        return\n",
    "\n",
    "    t_start = time()\n",
    "\n",
    "    user_counts = df.groupby(\"user_id\").size()\n",
    "    user_subset = np.in1d(\n",
    "        df.user_id, user_counts[user_counts >= item_min].index\n",
    "    )\n",
    "\n",
    "    filter_df = df[user_subset].reset_index(drop=True)\n",
    "\n",
    "    # find items with 10 or more users\n",
    "    item_counts = filter_df.groupby(\"item_id\").size()\n",
    "    item_subset = np.in1d(\n",
    "        filter_df.item_id, item_counts[item_counts >= user_min].index\n",
    "    )\n",
    "\n",
    "    filter_df = filter_df[item_subset].reset_index(drop=True)\n",
    "\n",
    "    user_counts = filter_df.groupby(\"user_id\").size()\n",
    "    user_subset = np.in1d(filter_df.user_id, user_counts[user_counts >= item_min].index)\n",
    "\n",
    "    filter_df = filter_df[user_subset].reset_index(drop=True)\n",
    "\n",
    "    t_end = time()\n",
    "\n",
    "#     assert (filter_df.groupby(\"user_id\").size() < 5).sum() == 0\n",
    "#     assert (filter_df.groupby(\"item_id\").size() < 5).sum() == 0\n",
    "\n",
    "    print(filter_df.nunique())\n",
    "    print(filter_df.shape)\n",
    "    print(\"{:.2f} Seconds\".format(t_end - t_start))\n",
    "\n",
    "    return filter_df\n",
    "\n",
    "def reset_df(df):\n",
    "    item_enc = LabelEncoder()\n",
    "    df['news_id'] = df[\"item_id\"]\n",
    "    df[\"item_id\"] = item_enc.fit_transform(df[\"item_id\"])\n",
    "\n",
    "    user_enc = LabelEncoder()\n",
    "    df[\"user_id\"] = user_enc.fit_transform(df[\"user_id\"])\n",
    "\n",
    "    assert df.user_id.min() == 0\n",
    "    assert df.item_id.min() == 0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id    20166\n",
      "item_id    12550\n",
      "dtype: int64\n",
      "(4596882, 2)\n",
      "0.96 Seconds\n"
     ]
    }
   ],
   "source": [
    "filtered_df = reset_df(filter_df(train_df, user_min, item_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bpr_mat(dataframe, threshold = 3):\n",
    "    tempdf = dataframe.copy()\n",
    "\n",
    "    # Vì tập dữ liệu này đánh index từ 1 nên chuyển sang kiểu category\n",
    "    # để tránh việc chúng ta có ma trận\n",
    "    tempdf['user_id'] = tempdf['user_id'].astype('category')\n",
    "    tempdf['item_id'] = tempdf['item_id'].astype('category')\n",
    "    tempdf['positive'] = 1\n",
    "\n",
    "    bpr_mat = csr_matrix((tempdf['positive'], (tempdf['user_id'].cat.codes, tempdf['item_id'].cat.codes)))\n",
    "    bpr_mat.eliminate_zeros()\n",
    "    del tempdf\n",
    "    return bpr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_mat = convert_to_bpr_mat(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20166, 12550)\n"
     ]
    }
   ],
   "source": [
    "print(bpr_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_train_test(bpr_mat, test_ratio = 0.2, verbose=True):\n",
    "    \"\"\"\n",
    "    Chia tập dữ liệu ra thành tập train & tập test\n",
    "\n",
    "    :param bpr_mat: ma trận bpr\n",
    "    :param test_ratio: float - tỉ lệ test set\n",
    "\n",
    "    :return train: ma trận bpr train\n",
    "    :return test: ma trận bpr test\n",
    "    \"\"\"\n",
    "    # Số lượng người dùng\n",
    "    n_users = bpr_mat.shape[0]\n",
    "    # Dùng ma trận thưa Dictionary Of Keys tối ưu hơn cho công đoạn này\n",
    "    train = bpr_mat.copy().todok()\n",
    "    test = dok_matrix(train.shape) # Lưu ý hiện tại test là ma trận 0\n",
    "\n",
    "    # với mỗi người dùng u\n",
    "    # chia số trường hợp nên khuyến nghị với tỉ lệ test_ratio đươc cho\n",
    "    # phần nào thuộc về test\n",
    "    for u in range(n_users):\n",
    "        split_index = bpr_mat[u].indices\n",
    "        # đếm số trường hợp nên khuyến nghị\n",
    "        count_positive = split_index.shape[0]\n",
    "        n_splits = max(min(math.ceil(test_ratio * count_positive), count_positive - 1), 1)\n",
    "        test_index = np.random.choice(split_index, size=n_splits, replace=False)\n",
    "        # Xem như dữ liệu chưa biết trong tập train\n",
    "        train[u, test_index] = 0\n",
    "        # Xem như dữ liệu nhìn thấy trong tập test\n",
    "        test[u, test_index] = 1\n",
    "\n",
    "    train, test = train.tocsr(), test.tocsr()\n",
    "\n",
    "    # Nếu cần in thông tin ra ngoài\n",
    "    if verbose:\n",
    "        print('BPR matrix with %d stored elements' % bpr_mat.nnz)\n",
    "        print('Train matrix with %d stored elements' % train.nnz)\n",
    "        print('Test matrix with %d stored elements' % test.nnz)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPR matrix with 666544 stored elements\n",
      "Train matrix with 58723 stored elements\n",
      "Test matrix with 607821 stored elements\n"
     ]
    }
   ],
   "source": [
    "bpr_train, bpr_test = split_to_train_test(bpr_mat, test_ratio=test_ratio, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bpr(W, H, user=None):\n",
    "    \"\"\"\n",
    "    Hàm trả về X_hat\n",
    "\n",
    "    :param W: ma trận W từ MF\n",
    "    :param H: ma trận H từ MF\n",
    "    :param user: người dùng (nếu None mặt định trả về tất cả)\n",
    "\n",
    "    :return predict_scores: điểm dự đoán từ BPR MF\n",
    "    \"\"\"\n",
    "    if user is None:\n",
    "        return W @ H.T\n",
    "    else:\n",
    "        return W[user] @ H.T\n",
    "\n",
    "def recommend_bpr(bpr_matrix, predict_score, user, n_rmd_items=None):\n",
    "    \"\"\"\n",
    "    Dự đoán những sản phẩm mà người dùng muốn mua\n",
    "    Những sản phẩm nào đã thích rồi thì không trả về nữa\n",
    "    Trả về index theo bpr_matrix (đánh từ 0)\n",
    "\n",
    "    :param bpr_matrix: ma trận bpr hiện tại\n",
    "    :param predict_score: điểm dự đoán các item\n",
    "    :param user: số thứ tự người dùng của predict score\n",
    "    :param n_rmd_items: số lượng sản phẩm trả về, mặc định tất cả\n",
    "\n",
    "    :return rmd_items: danh sách các sản phẩm khuyến nghị\n",
    "    \"\"\"\n",
    "    # Số lượng sản phẩm\n",
    "    n_items = bpr_matrix.shape[1]\n",
    "    # những sản phẩm đã thích rồi\n",
    "    liked_items = bpr_matrix[user].indices\n",
    "    scores = predict_score.copy()\n",
    "\n",
    "    # index ban đầu khi chưa sắp xếp\n",
    "    sort_index = np.arange(0, n_items)\n",
    "\n",
    "    # Xóa các sản phẩm đã mua\n",
    "    sort_index = np.delete(sort_index, liked_items)\n",
    "    scores = np.delete(scores, liked_items)\n",
    "\n",
    "    # sắp xếp và trả về theo số thứ tự của score\n",
    "    arg_sort = np.argsort(-scores)\n",
    "\n",
    "    # dùng sort_index để lấy số thứ tự ban đầu\n",
    "    rmd_items = sort_index[arg_sort]\n",
    "\n",
    "    if len(rmd_items) >= n_rmd_items and n_rmd_items is not None:\n",
    "        rmd_items = rmd_items[: n_rmd_items]\n",
    "    return rmd_items\n",
    "\n",
    "def auc_score(predict_mat, bpr_mat):\n",
    "    \"\"\"\n",
    "    Tính Area under the ROC curve (AUC)\n",
    "    cho bài toán hệ khuyến nghị\n",
    "\n",
    "    :param predict_mat: ma trận dữ đoán bpr mf\n",
    "    :param bpr_mat: ma trận train hoặc test\n",
    "    :return auc: area under the roc curve\n",
    "    \"\"\"\n",
    "    auc = 0.0\n",
    "    n_users, n_items = bpr_mat.shape\n",
    "\n",
    "    # u và row tương ứng user và bp\n",
    "    for u in range(n_users):\n",
    "        y_pred = predict_mat[u]\n",
    "        y_true = np.zeros(n_items)\n",
    "        y_true[bpr_mat[u].indices] = 1\n",
    "        try:\n",
    "            auc += roc_auc_score(y_true, y_pred)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    auc /= n_users\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return 2 * sigmoid(2 * x) - 1\n",
    "\n",
    "def learn_bpr_mf_sgd(bpr_mat, pos, neg, mapper, W = None, H = None, alpha=0.01, lamb=0.01, k=12, n_iters=10000, initial_value=2):\n",
    "    \"\"\"\n",
    "    Thuật toán học BPR MF SGD (một điểm dữ liệu duy nhất)\n",
    "\n",
    "    :param bpr_mat: ma trận bpr\n",
    "    :param alpha: hệ số learning rate\n",
    "    :param lamb: hệ số lambda của bình thường hóa regularization\n",
    "    :param k: số lượng latent factor trong bài toán MF\n",
    "    :param n_iters: số vòng lặp\n",
    "\n",
    "    :return W: ma trận W\n",
    "    :return H: ma trận H\n",
    "    \"\"\"\n",
    "    \n",
    "    # subset specifies\n",
    "    print('initialize similarity model...', end=' ')\n",
    "    sim_model = Similarity\n",
    "    print('done!')\n",
    "    \n",
    "    n_users, n_items = bpr_mat.shape\n",
    "    # Khởi tạo ma trận W và ma trận H\n",
    "    if W is None:\n",
    "        W = np.empty(shape=(n_users, k))\n",
    "        W.fill(initial_value)\n",
    "        \n",
    "        W = np.random.rand(n_users, k)\n",
    "    if H is None:\n",
    "        H = np.empty(shape=(n_items, k))\n",
    "        H.fill(initial_value)\n",
    "        H = np.random.rand(n_items, k)\n",
    "\n",
    "    # lặp\n",
    "    for _ in range(n_iters):\n",
    "        # ngẫu nghiên 3 bộ (u,i,j) từ D_S\n",
    "        u = np.random.randint(0, n_users)\n",
    "        if len(pos[u]) == 0:\n",
    "            continue\n",
    "        i = pos[u][np.random.randint(0, len(pos[u]))]\n",
    "        j = neg[u][np.random.randint(0, len(neg[u]))]\n",
    "\n",
    "        # Tính xuij\n",
    "        xui = (W[u] * H[i]).sum()\n",
    "        xuj = (W[u] * H[j]).sum()\n",
    "        xuij = tanh(xui - xuj)\n",
    "        \n",
    "#         if (sim_model.similarity(mapper[i], mapper[j]) != 1):\n",
    "#             xuij = xuij * (1 - sim_model.similarity(mapper[i], mapper[j]))\n",
    "\n",
    "        # mũ tự nhiên e của xuij\n",
    "        exp_xuij = np.exp(xuij)\n",
    "\n",
    "        # sgd cho tham số Theta (W và H)\n",
    "        W[u] = W[u] + alpha * ( exp_xuij / (1+exp_xuij) * (H[i] - H[j]) + lamb * W[u])\n",
    "        H[i] = H[i] + alpha * ( exp_xuij / (1+exp_xuij) * W[u] + lamb * H[i])\n",
    "        H[j] = H[j] + alpha * ( exp_xuij / (1+exp_xuij) * (-W[u]) + lamb * H[j])\n",
    "    return W, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, H = None, None\n",
    "\n",
    "# Tập các sản phẩm nên khuyến nghị\n",
    "pos = np.split(bpr_train.indices, bpr_train.indptr)[1:-1]\n",
    "# Tập các sản phẩm không nên khuyến nghị\n",
    "neg = [np.setdiff1d(np.arange(0, bpr_train.shape[1], 1), e) for e in pos]\n",
    "\n",
    "mapper = pd.Series(filtered_df[\"news_id\"].values,index=filtered_df['item_id']).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize similarity model... done!\n",
      "AUC of train: 0.669219\n",
      "AUC of test : 0.652396\n"
     ]
    }
   ],
   "source": [
    "W, H = learn_bpr_mf_sgd(\n",
    "    bpr_train,\n",
    "    pos,\n",
    "    neg,\n",
    "    mapper,\n",
    "    W = W,\n",
    "    H = H,\n",
    "    alpha=alpha,\n",
    "    lamb=lamb,\n",
    "    k=k,\n",
    "    n_iters=n_iters,\n",
    "    initial_value = initial_value\n",
    ")\n",
    "\n",
    "pred = predict_bpr(W, H)\n",
    "\n",
    "train_score = auc_score(pred, bpr_train)\n",
    "test_score = auc_score(pred, bpr_test)\n",
    "print('AUC of train: %f' % train_score)\n",
    "print('AUC of test : %f' % test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = os.path.join('./result', datetime.now().strftime(\"%d-%m-%Y %H-%M\"))\n",
    "\n",
    "pathlib.Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(output_folder, result_train_file + '_W.npy'), W)\n",
    "np.save(os.path.join(output_folder, result_train_file + '_H.npy'), H)\n",
    "\n",
    "with open(os.path.join(output_folder, result_train_file + '.txt'), 'w') as file:\n",
    "    file.write(\"Parameters:\\n\\n\")\n",
    "    file.write('user min: %i' % user_min + \"\\n\")\n",
    "    file.write('item min: %i' % item_min + \"\\n\")\n",
    "    file.write('test ratio: %f' % test_ratio + \"\\n\")\n",
    "    file.write('alpha: %f' % alpha + \"\\n\")\n",
    "    file.write('lambda: %f' % lamb + \"\\n\")\n",
    "    file.write('k: %i' % k + \"\\n\")\n",
    "    file.write('n iters: %i' % n_iters + \"\\n\")\n",
    "    file.write('AUC-Train: %f' % train_score + \"\\n\")\n",
    "    file.write('AUC-Test: %f' % test_score + \"\\n\")\n",
    "    file.write(\"---------------------\\n\")\n",
    "    file.write('Total users: %i \\n' % train_df.nunique()[0])\n",
    "    file.write('Total items: %i \\n' % train_df.nunique()[1])\n",
    "    file.write('Total interacts: %i \\n' % train_df.shape[0])\n",
    "    file.write('No training users: %i \\n' % filtered_df.nunique()[0])\n",
    "    file.write('No training items: %i \\n' % filtered_df.nunique()[1])\n",
    "    file.write('BPR matrix with %d stored elements\\n' % bpr_mat.nnz)\n",
    "    file.write('Train matrix with %d stored elements\\n' % bpr_train.nnz)\n",
    "    file.write('Test matrix with %d stored elements\\n' % bpr_test.nnz)\n",
    "    file.write('Matrix initial with %d' % initial_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   46  6144  8256 10703   161]\n"
     ]
    }
   ],
   "source": [
    "u = 300\n",
    "n_rmd_items = 5\n",
    "score = predict_bpr(W, H, u)\n",
    "rmd_items = recommend_bpr(bpr_train, score, u, n_rmd_items)\n",
    "print(rmd_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (W @ H.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.570187486663785\n",
      "46.737755901691095\n",
      "15.039560983331006\n"
     ]
    }
   ],
   "source": [
    "print(result.min())\n",
    "print(result.max())\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.27309718, 16.02198202, 14.57414907, ..., 13.09773195,\n",
       "        12.09906051, 15.45219733],\n",
       "       [15.10687976, 15.6346085 , 15.26079341, ..., 14.62642288,\n",
       "        12.69462948, 15.4580041 ],\n",
       "       [16.77814881, 14.95172002, 16.89846842, ..., 13.22637816,\n",
       "        13.43220599, 15.47784065],\n",
       "       ...,\n",
       "       [15.64023993, 16.5201007 , 17.36820457, ..., 12.98550794,\n",
       "        15.27807669, 15.63118303],\n",
       "       [16.81492921, 17.36222565, 18.98478901, ..., 16.04367748,\n",
       "        13.29970778, 17.29802435],\n",
       "       [14.90673124, 16.41114687, 16.51085476, ..., 12.81657767,\n",
       "        12.88300499, 15.8269745 ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tham khảo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner and Lars Schmidt-Thieme. BPR: Bayesian Personalized Ranking from Implicit Feedback. \n",
    "02. Weike Panand, Li Chen. GBPR: Group Preference Based Bayesian Personalized Ranking for One-Class Collaborative Filtering. Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence. https://www.aaai.org/ocs/index.php/IJCAI/IJCAI13/paper/viewFile/6316/7124\n",
    "03. Michael D. Ekstrand, Joseph A Konstan. Personalized Ranking (with Daniel Kluver). Matrix Factorization and Advanced Techniques - University of Minnesota. https://www.coursera.org/lecture/matrix-factorization/personalized-ranking-with-daniel-kluver-s3XJo\n",
    "04. Kim Falk. Practical Recommender Systems. Manning Publications.\n",
    "05. Ethen (MingYu) Liu. Bayesian Personalized Ranking. http://ethen8181.github.io/machine-learning/recsys/4_bpr.html\n",
    "06. Alfredo Láinez Rodrigo, Luke de Oliveira. Distributed Bayesian Personalized Ranking in Spark. https://stanford.edu/~rezab/classes/cme323/S16/projects_reports/rodrigo_oliveira.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
