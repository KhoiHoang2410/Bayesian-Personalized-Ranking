{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPR Bayesian Personalized Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ThetaLog.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load các thư viện cần thiết\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix, dok_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.random.seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './MINDsmall_train/behaviors.tsv'\n",
    "output_train_path = './datafile/small_train.csv'\n",
    "\n",
    "result_train_file = 'bpr_mf'\n",
    "\n",
    "test_ratio = 0.3\n",
    "\n",
    "alpha=0.001\n",
    "lamb=0.02\n",
    "k=60\n",
    "training_per_interact = 10\n",
    "initial_value = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_behaviors(path):\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        sep='\\t',\n",
    "        names = [\"id\", \"user_id\", 'created_at', \"history\", \"impressions\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def write_file(df, path):\n",
    "    t_start = time()\n",
    "    print(\"Processing\", path)\n",
    "    with open(path, \"w\") as file:\n",
    "        for i, row in df.iterrows():\n",
    "            for new_id in str(row.history).split(' '):\n",
    "                if row.user_id[1:].isnumeric() and new_id[1:].isnumeric():\n",
    "                    file.write(row.user_id[1:] + \",\" + new_id[1:] + \"\\n\")\n",
    "\n",
    "    t_end = time()\n",
    "    print(\"Processed in: {:.2f} Seconds\".format(t_end - t_start))\n",
    "\n",
    "def write_data_file(train_path, output_train_path):\n",
    "    train_df = load_behaviors(train_path)\n",
    "\n",
    "    write_file(train_df, output_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_data_file(train_path, output_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        header=None,\n",
    "        names=['user_id', 'item_id']\n",
    "    )\n",
    "    df.reindex(columns = ['user_id', 'item_id'])\n",
    "    return df.reset_index(drop = True)\n",
    "\n",
    "def load_data(train_path):\n",
    "    train_df = load_file(train_path)\n",
    "    \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data(output_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, user_min, item_min):\n",
    "    if df is None:\n",
    "        return\n",
    "\n",
    "    t_start = time()\n",
    "\n",
    "    user_counts = df.groupby(\"user_id\").size()\n",
    "    user_subset = np.in1d(\n",
    "        df.user_id, user_counts[user_counts >= item_min].index\n",
    "    )\n",
    "\n",
    "    filter_df = df[user_subset].reset_index(drop=True)\n",
    "\n",
    "    # find items with 10 or more users\n",
    "    item_counts = filter_df.groupby(\"item_id\").size()\n",
    "    item_subset = np.in1d(\n",
    "        filter_df.item_id, item_counts[item_counts >= user_min].index\n",
    "    )\n",
    "\n",
    "    filter_df = filter_df[item_subset].reset_index(drop=True)\n",
    "\n",
    "    user_counts = filter_df.groupby(\"user_id\").size()\n",
    "    user_subset = np.in1d(filter_df.user_id, user_counts[user_counts >= item_min].index)\n",
    "\n",
    "    filter_df = filter_df[user_subset].reset_index(drop=True)\n",
    "\n",
    "    t_end = time()\n",
    "\n",
    "#     assert (filter_df.groupby(\"user_id\").size() < 5).sum() == 0\n",
    "#     assert (filter_df.groupby(\"item_id\").size() < 5).sum() == 0\n",
    "\n",
    "    print(filter_df.nunique())\n",
    "    print(filter_df.shape)\n",
    "    print(\"{:.2f} Seconds\".format(t_end - t_start))\n",
    "\n",
    "    return filter_df\n",
    "\n",
    "def reset_df(df):\n",
    "    item_enc = LabelEncoder()\n",
    "    df['news_id'] = df[\"item_id\"]\n",
    "    df[\"item_id\"] = item_enc.fit_transform(df[\"item_id\"])\n",
    "\n",
    "    user_enc = LabelEncoder()\n",
    "    df[\"user_id\"] = user_enc.fit_transform(df[\"user_id\"])\n",
    "\n",
    "    assert df.user_id.min() == 0\n",
    "    assert df.item_id.min() == 0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(\"user_id\").size().describe()[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user min: 104\n",
      "item min: 153\n"
     ]
    }
   ],
   "source": [
    "# user_min = int(train_df.groupby(\"user_id\").size().describe()[5])\n",
    "# item_min = int(train_df.groupby(\"item_id\").size().describe()[5])\n",
    "user_min = int(train_df.groupby(\"user_id\").size().mean())\n",
    "item_min = int(train_df.groupby(\"item_id\").size().mean())\n",
    "\n",
    "print('user min: %i\\nitem min: %i' % (user_min, item_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id    6124\n",
      "item_id    6463\n",
      "dtype: int64\n",
      "(3285644, 2)\n",
      "1.02 Seconds\n"
     ]
    }
   ],
   "source": [
    "filtered_df = reset_df(filter_df(train_df, user_min, item_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bpr_mat(dataframe, threshold = 3):\n",
    "    tempdf = dataframe.copy()\n",
    "\n",
    "    # Vì tập dữ liệu này đánh index từ 1 nên chuyển sang kiểu category\n",
    "    # để tránh việc chúng ta có ma trận\n",
    "    tempdf['user_id'] = tempdf['user_id'].astype('category')\n",
    "    tempdf['item_id'] = tempdf['item_id'].astype('category')\n",
    "    tempdf['positive'] = 1\n",
    "\n",
    "    bpr_mat = csr_matrix((tempdf['positive'], (tempdf['user_id'].cat.codes, tempdf['item_id'].cat.codes)))\n",
    "    bpr_mat.eliminate_zeros()\n",
    "    del tempdf\n",
    "    return bpr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_mat = convert_to_bpr_mat(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6124, 6463)\n"
     ]
    }
   ],
   "source": [
    "print(bpr_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_train_test(bpr_mat, test_ratio = 0.2, verbose=True):\n",
    "    \"\"\"\n",
    "    Chia tập dữ liệu ra thành tập train & tập test\n",
    "\n",
    "    :param bpr_mat: ma trận bpr\n",
    "    :param test_ratio: float - tỉ lệ test set\n",
    "\n",
    "    :return train: ma trận bpr train\n",
    "    :return test: ma trận bpr test\n",
    "    \"\"\"\n",
    "    # Số lượng người dùng\n",
    "    n_users = bpr_mat.shape[0]\n",
    "    # Dùng ma trận thưa Dictionary Of Keys tối ưu hơn cho công đoạn này\n",
    "    train = bpr_mat.copy().todok()\n",
    "    test = dok_matrix(train.shape) # Lưu ý hiện tại test là ma trận 0\n",
    "\n",
    "    # với mỗi người dùng u\n",
    "    # chia số trường hợp nên khuyến nghị với tỉ lệ test_ratio đươc cho\n",
    "    # phần nào thuộc về test\n",
    "    for u in range(n_users):\n",
    "        split_index = bpr_mat[u].indices\n",
    "        # đếm số trường hợp nên khuyến nghị\n",
    "        count_positive = split_index.shape[0]\n",
    "        n_splits = max(min(math.ceil(test_ratio * count_positive), count_positive - 1), 1)\n",
    "        test_index = np.random.choice(split_index, size=n_splits, replace=False)\n",
    "        # Xem như dữ liệu chưa biết trong tập train\n",
    "        train[u, test_index] = 0\n",
    "        # Xem như dữ liệu nhìn thấy trong tập test\n",
    "        test[u, test_index] = 1\n",
    "\n",
    "    train, test = train.tocsr(), test.tocsr()\n",
    "\n",
    "    # Nếu cần in thông tin ra ngoài\n",
    "    if verbose:\n",
    "        print('BPR matrix with %d stored elements' % bpr_mat.nnz)\n",
    "        print('Train matrix with %d stored elements' % train.nnz)\n",
    "        print('Test matrix with %d stored elements' % test.nnz)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPR matrix with 335627 stored elements\n",
      "Train matrix with 232200 stored elements\n",
      "Test matrix with 103427 stored elements\n"
     ]
    }
   ],
   "source": [
    "bpr_train, bpr_test = split_to_train_test(bpr_mat, test_ratio=test_ratio, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n iters: 2322000\n"
     ]
    }
   ],
   "source": [
    "n_iters = training_per_interact * bpr_train.nnz\n",
    "print('n iters: %i' % n_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bpr(W, H, user=None):\n",
    "    \"\"\"\n",
    "    Hàm trả về X_hat\n",
    "\n",
    "    :param W: ma trận W từ MF\n",
    "    :param H: ma trận H từ MF\n",
    "    :param user: người dùng (nếu None mặt định trả về tất cả)\n",
    "\n",
    "    :return predict_scores: điểm dự đoán từ BPR MF\n",
    "    \"\"\"\n",
    "    if user is None:\n",
    "        return W @ H.T\n",
    "    else:\n",
    "        return W[user] @ H.T\n",
    "\n",
    "def recommend_bpr(bpr_matrix, predict_score, user, n_rmd_items=None):\n",
    "    \"\"\"\n",
    "    Dự đoán những sản phẩm mà người dùng muốn mua\n",
    "    Những sản phẩm nào đã thích rồi thì không trả về nữa\n",
    "    Trả về index theo bpr_matrix (đánh từ 0)\n",
    "\n",
    "    :param bpr_matrix: ma trận bpr hiện tại\n",
    "    :param predict_score: điểm dự đoán các item\n",
    "    :param user: số thứ tự người dùng của predict score\n",
    "    :param n_rmd_items: số lượng sản phẩm trả về, mặc định tất cả\n",
    "\n",
    "    :return rmd_items: danh sách các sản phẩm khuyến nghị\n",
    "    \"\"\"\n",
    "    # Số lượng sản phẩm\n",
    "    n_items = bpr_matrix.shape[1]\n",
    "    # những sản phẩm đã thích rồi\n",
    "    liked_items = bpr_matrix[user].indices\n",
    "    scores = predict_score.copy()\n",
    "\n",
    "    # index ban đầu khi chưa sắp xếp\n",
    "    sort_index = np.arange(0, n_items)\n",
    "\n",
    "    # Xóa các sản phẩm đã mua\n",
    "    sort_index = np.delete(sort_index, liked_items)\n",
    "    scores = np.delete(scores, liked_items)\n",
    "\n",
    "    # sắp xếp và trả về theo số thứ tự của score\n",
    "    arg_sort = np.argsort(-scores)\n",
    "\n",
    "    # dùng sort_index để lấy số thứ tự ban đầu\n",
    "    rmd_items = sort_index[arg_sort]\n",
    "\n",
    "    if len(rmd_items) >= n_rmd_items and n_rmd_items is not None:\n",
    "        rmd_items = rmd_items[: n_rmd_items]\n",
    "    return rmd_items\n",
    "\n",
    "def auc_score(predict_mat, bpr_mat):\n",
    "    \"\"\"\n",
    "    Tính Area under the ROC curve (AUC)\n",
    "    cho bài toán hệ khuyến nghị\n",
    "\n",
    "    :param predict_mat: ma trận dữ đoán bpr mf\n",
    "    :param bpr_mat: ma trận train hoặc test\n",
    "    :return auc: area under the roc curve\n",
    "    \"\"\"\n",
    "    auc = 0.0\n",
    "    n_users, n_items = bpr_mat.shape\n",
    "\n",
    "    # u và row tương ứng user và bp\n",
    "    for u in range(n_users):\n",
    "        y_pred = predict_mat[u]\n",
    "        y_true = np.zeros(n_items)\n",
    "        y_true[bpr_mat[u].indices] = 1\n",
    "        try:\n",
    "            auc += roc_auc_score(y_true, y_pred)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    auc /= n_users\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_error(W, H, pos):\n",
    "    n_user = len(pos)\n",
    "    pred = []\n",
    "    result = []\n",
    "    print('calculating MSE error - ', end = '')\n",
    "    for u in range(n_user):\n",
    "        predict_u = predict_bpr(W, H, user=u)\n",
    "\n",
    "        argsort_predict_u = np.flip(np.argsort(predict_u))\n",
    "        intersect = np.intersect1d(argsort_predict_u[:len(pos[u])], pos[u])\n",
    "        pred.append(intersect.size)\n",
    "        result.append(pos[u].size)\n",
    "    print(mean_squared_error(pred, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_bpr_mf_sgd(bpr_mat, pos, neg, W = None, H = None, alpha=0.01, lamb=0.01, k=12, n_iters=10000, initial_value=2):\n",
    "    \"\"\"\n",
    "    Thuật toán học BPR MF SGD (một điểm dữ liệu duy nhất)\n",
    "\n",
    "    :param bpr_mat: ma trận bpr\n",
    "    :param alpha: hệ số learning rate\n",
    "    :param lamb: hệ số lambda của bình thường hóa regularization\n",
    "    :param k: số lượng latent factor trong bài toán MF\n",
    "    :param n_iters: số vòng lặp\n",
    "\n",
    "    :return W: ma trận W\n",
    "    :return H: ma trận H\n",
    "    \"\"\"\n",
    "    \n",
    "    n_users, n_items = bpr_mat.shape\n",
    "    # Khởi tạo ma trận W và ma trận H\n",
    "    if W is None:\n",
    "        W = np.empty(shape=(n_users, k))\n",
    "        W.fill(initial_value)\n",
    "    if H is None:\n",
    "        H = np.empty(shape=(n_items, k))\n",
    "        H.fill(initial_value)\n",
    "\n",
    "    # lặp\n",
    "    for idx in range(n_iters):\n",
    "        # ngẫu nghiên 3 bộ (u,i,j) từ D_S\n",
    "        u = np.random.randint(0, n_users)\n",
    "        if len(pos[u]) == 0:\n",
    "            continue\n",
    "        i = pos[u][np.random.randint(0, len(pos[u]))]\n",
    "        j = neg[u][np.random.randint(0, len(neg[u]))]\n",
    "\n",
    "        # Tính xuij\n",
    "        xui = (W[u] * H[i]).sum()\n",
    "        xuj = (W[u] * H[j]).sum()\n",
    "        xuij = np.tanh(xui - xuj)\n",
    "\n",
    "        # mũ tự nhiên e của xuij\n",
    "        exp_xuij = np.exp(xuij)\n",
    "\n",
    "        # sgd cho tham số Theta (W và H)\n",
    "        W[u] = W[u] + alpha * ( exp_xuij / (1+exp_xuij) * (H[i] - H[j]) + lamb * W[u])\n",
    "        H[i] = H[i] + alpha * ( exp_xuij / (1+exp_xuij) * W[u] + lamb * H[i])\n",
    "        H[j] = H[j] + alpha * ( exp_xuij / (1+exp_xuij) * (-W[u]) + lamb * H[j])\n",
    "\n",
    "        if (idx + 1) % 10000 == 0:\n",
    "            print('Iter: %i' % (idx + 1))\n",
    "            calc_error(W, H, pos)\n",
    "    return W, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tập các sản phẩm nên khuyến nghị\n",
    "pos = np.split(bpr_train.indices, bpr_train.indptr)[1:-1]\n",
    "# Tập các sản phẩm không nên khuyến nghị\n",
    "neg = [np.setdiff1d(np.arange(0, bpr_train.shape[1], 1), e) for e in pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, H = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 10000\n",
      "calculating MSE error - 1620.814826910516\n",
      "Iter: 20000\n",
      "calculating MSE error - 1611.9866100587851\n",
      "Iter: 30000\n",
      "calculating MSE error - 1610.2437949052908\n",
      "Iter: 40000\n",
      "calculating MSE error - 1608.1975832789026\n",
      "Iter: 50000\n",
      "calculating MSE error - 1607.305682560418\n",
      "Iter: 60000\n",
      "calculating MSE error - 1606.7970280862182\n",
      "Iter: 70000\n",
      "calculating MSE error - 1604.8572828216852\n",
      "Iter: 80000\n",
      "calculating MSE error - 1604.4428478118878\n",
      "Iter: 90000\n",
      "calculating MSE error - 1604.2813520574787\n",
      "Iter: 100000\n",
      "calculating MSE error - 1603.7705747877205\n",
      "Iter: 110000\n",
      "calculating MSE error - 1603.8037230568257\n",
      "Iter: 120000\n",
      "calculating MSE error - 1604.4239059438275\n",
      "Iter: 130000\n",
      "calculating MSE error - 1605.370509470934\n",
      "Iter: 140000\n",
      "calculating MSE error - 1604.5109405617243\n",
      "Iter: 150000\n",
      "calculating MSE error - 1604.4041476159373\n",
      "Iter: 160000\n",
      "calculating MSE error - 1603.8804702808623\n",
      "Iter: 170000\n",
      "calculating MSE error - 1604.096342259961\n",
      "Iter: 180000\n",
      "calculating MSE error - 1604.3850424559112\n",
      "Iter: 190000\n",
      "calculating MSE error - 1604.8231548007839\n",
      "Iter: 200000\n",
      "calculating MSE error - 1604.8125408229914\n",
      "Iter: 210000\n",
      "calculating MSE error - 1604.9100261267145\n",
      "Iter: 220000\n",
      "calculating MSE error - 1605.3579359895493\n",
      "Iter: 230000\n",
      "calculating MSE error - 1605.2855976485957\n",
      "Iter: 240000\n",
      "calculating MSE error - 1605.1268778576093\n",
      "Iter: 250000\n",
      "calculating MSE error - 1604.3651208360548\n",
      "Iter: 260000\n",
      "calculating MSE error - 1604.2767798824298\n",
      "Iter: 270000\n",
      "calculating MSE error - 1604.607119529719\n",
      "Iter: 280000\n",
      "calculating MSE error - 1604.5689092096668\n",
      "Iter: 290000\n",
      "calculating MSE error - 1604.7413455258002\n",
      "Iter: 300000\n",
      "calculating MSE error - 1604.8171129980406\n",
      "Iter: 310000\n",
      "calculating MSE error - 1605.1464728935337\n",
      "Iter: 320000\n",
      "calculating MSE error - 1604.9648922273025\n",
      "Iter: 330000\n",
      "calculating MSE error - 1604.56466361855\n",
      "Iter: 340000\n",
      "calculating MSE error - 1604.9746897452646\n",
      "Iter: 350000\n",
      "calculating MSE error - 1604.6446766819072\n",
      "Iter: 360000\n",
      "calculating MSE error - 1604.6512083605487\n",
      "Iter: 370000\n",
      "calculating MSE error - 1604.5086544741998\n",
      "Iter: 380000\n",
      "calculating MSE error - 1604.3729588504245\n",
      "Iter: 390000\n",
      "calculating MSE error - 1604.833115610712\n",
      "Iter: 400000\n",
      "calculating MSE error - 1604.5765839320704\n",
      "Iter: 410000\n",
      "calculating MSE error - 1603.814337034618\n",
      "Iter: 420000\n",
      "calculating MSE error - 1604.0667864141085\n",
      "Iter: 430000\n",
      "calculating MSE error - 1604.0689092096668\n",
      "Iter: 440000\n",
      "calculating MSE error - 1603.9278249510123\n",
      "Iter: 450000\n",
      "calculating MSE error - 1604.190235140431\n",
      "Iter: 460000\n",
      "calculating MSE error - 1603.661822338341\n",
      "Iter: 470000\n",
      "calculating MSE error - 1603.7251796211626\n",
      "Iter: 480000\n",
      "calculating MSE error - 1603.8500979751796\n",
      "Iter: 490000\n",
      "calculating MSE error - 1603.7537557152189\n",
      "Iter: 500000\n",
      "calculating MSE error - 1604.0445787067276\n",
      "Iter: 510000\n",
      "calculating MSE error - 1603.911659046375\n",
      "Iter: 520000\n",
      "calculating MSE error - 1603.7746570868712\n",
      "Iter: 530000\n",
      "calculating MSE error - 1604.2049314173742\n",
      "Iter: 540000\n",
      "calculating MSE error - 1603.7607772697584\n",
      "Iter: 550000\n",
      "calculating MSE error - 1603.8863487916394\n",
      "Iter: 560000\n",
      "calculating MSE error - 1603.861528412802\n",
      "Iter: 570000\n",
      "calculating MSE error - 1604.212606139778\n",
      "Iter: 580000\n",
      "calculating MSE error - 1604.1425538863489\n",
      "Iter: 590000\n",
      "calculating MSE error - 1604.259307642064\n",
      "Iter: 600000\n",
      "calculating MSE error - 1604.4180274330504\n",
      "Iter: 610000\n",
      "calculating MSE error - 1604.3130306988896\n",
      "Iter: 620000\n",
      "calculating MSE error - 1604.555682560418\n",
      "Iter: 630000\n",
      "calculating MSE error - 1604.4059438275638\n",
      "Iter: 640000\n",
      "calculating MSE error - 1604.5538863487916\n",
      "Iter: 650000\n",
      "calculating MSE error - 1604.7792292619204\n",
      "Iter: 660000\n",
      "calculating MSE error - 1604.7003592423252\n",
      "Iter: 670000\n",
      "calculating MSE error - 1604.542455911169\n",
      "Iter: 680000\n",
      "calculating MSE error - 1604.4573807968648\n",
      "Iter: 690000\n",
      "calculating MSE error - 1604.3721423905945\n",
      "Iter: 700000\n",
      "calculating MSE error - 1604.2942521227956\n",
      "Iter: 710000\n",
      "calculating MSE error - 1604.2932723709994\n",
      "Iter: 720000\n",
      "calculating MSE error - 1604.6004245591116\n",
      "Iter: 730000\n",
      "calculating MSE error - 1604.4978772044415\n",
      "Iter: 740000\n",
      "calculating MSE error - 1604.378837361202\n",
      "Iter: 750000\n",
      "calculating MSE error - 1604.9688112344872\n",
      "Iter: 760000\n",
      "calculating MSE error - 1604.846668843893\n",
      "Iter: 770000\n",
      "calculating MSE error - 1604.9433376877857\n",
      "Iter: 780000\n",
      "calculating MSE error - 1604.4890594382757\n",
      "Iter: 790000\n",
      "calculating MSE error - 1604.4635858915742\n",
      "Iter: 800000\n",
      "calculating MSE error - 1604.8536903984325\n",
      "Iter: 810000\n",
      "calculating MSE error - 1605.1755388634879\n",
      "Iter: 820000\n",
      "calculating MSE error - 1605.0876877857609\n",
      "Iter: 830000\n",
      "calculating MSE error - 1605.1092423252776\n",
      "Iter: 840000\n",
      "calculating MSE error - 1605.4934683213585\n",
      "Iter: 850000\n",
      "calculating MSE error - 1605.352057478772\n",
      "Iter: 860000\n",
      "calculating MSE error - 1605.193500979752\n",
      "Iter: 870000\n",
      "calculating MSE error - "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m W, H \u001b[38;5;241m=\u001b[39m \u001b[43mlearn_bpr_mf_sgd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbpr_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mW\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlamb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlamb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_value\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m pred \u001b[38;5;241m=\u001b[39m predict_bpr(W, H)\n\u001b[1;32m     16\u001b[0m train_score \u001b[38;5;241m=\u001b[39m auc_score(pred, bpr_train)\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mlearn_bpr_mf_sgd\u001b[0;34m(bpr_mat, pos, neg, W, H, alpha, lamb, k, n_iters, initial_value)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIter: \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 48\u001b[0m         \u001b[43mcalc_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m W, H\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mcalc_error\u001b[0;34m(W, H, pos)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalculating MSE error - \u001b[39m\u001b[38;5;124m'\u001b[39m, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_user):\n\u001b[0;32m----> 7\u001b[0m     predict_u \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_bpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     argsort_predict_u \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mflip(np\u001b[38;5;241m.\u001b[39margsort(predict_u))\n\u001b[1;32m     10\u001b[0m     intersect \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mintersect1d(argsort_predict_u[:\u001b[38;5;28mlen\u001b[39m(pos[u])], pos[u])\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mpredict_bpr\u001b[0;34m(W, H, user)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m W \u001b[38;5;241m@\u001b[39m H\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mW\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "W, H = learn_bpr_mf_sgd(\n",
    "    bpr_train,\n",
    "    pos,\n",
    "    neg,\n",
    "    W = W,\n",
    "    H = H,\n",
    "    alpha=alpha,\n",
    "    lamb=lamb,\n",
    "    k=k,\n",
    "    n_iters=n_iters,\n",
    "    initial_value = initial_value\n",
    ")\n",
    "\n",
    "pred = predict_bpr(W, H)\n",
    "\n",
    "train_score = auc_score(pred, bpr_train)\n",
    "test_score = auc_score(pred, bpr_test)\n",
    "print('AUC of train: %f' % train_score)\n",
    "print('AUC of test : %f' % test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_user = len(pos)\n",
    "pred = []\n",
    "result = []\n",
    "print('calculating MSE error - ', end = '')\n",
    "\n",
    "u = 1\n",
    "\n",
    "predict_u = predict_bpr(W, H, user=u)\n",
    "\n",
    "argsort_predict_u = np.flip(np.argsort(predict_u))\n",
    "intersect = np.intersect1d(argsort_predict_u[:len(pos[u])], pos[u])\n",
    "pred.append(intersect.size)\n",
    "result.append(pos[u].size)\n",
    "\n",
    "print(mean_squared_error(pred, result))\n",
    "print(argsort_predict_u[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = os.path.join('./result', datetime.now().strftime(\"%d-%m-%Y %H-%M\"))\n",
    "\n",
    "pathlib.Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(output_folder, result_train_file + '_W.npy'), W)\n",
    "np.save(os.path.join(output_folder, result_train_file + '_H.npy'), H)\n",
    "\n",
    "with open(os.path.join(output_folder, result_train_file + '.txt'), 'w') as file:\n",
    "    file.write(\"Parameters:\\n\\n\")\n",
    "    file.write('user min: %i' % user_min + \"\\n\")\n",
    "    file.write('item min: %i' % item_min + \"\\n\")\n",
    "    file.write('test ratio: %f' % test_ratio + \"\\n\")\n",
    "    file.write('alpha: %f' % alpha + \"\\n\")\n",
    "    file.write('lambda: %f' % lamb + \"\\n\")\n",
    "    file.write('k: %i' % k + \"\\n\")\n",
    "    file.write('n iters: %i' % n_iters + \"\\n\")\n",
    "    file.write('AUC-Train: %f' % train_score + \"\\n\")\n",
    "    file.write('AUC-Test: %f' % test_score + \"\\n\")\n",
    "    file.write(\"---------------------\\n\")\n",
    "    file.write('Total users: %i \\n' % train_df.nunique()[0])\n",
    "    file.write('Total items: %i \\n' % train_df.nunique()[1])\n",
    "    file.write('Total interacts: %i \\n' % train_df.shape[0])\n",
    "    file.write('No training users: %i \\n' % filtered_df.nunique()[0])\n",
    "    file.write('No training items: %i \\n' % filtered_df.nunique()[1])\n",
    "    file.write('BPR matrix with %d stored elements\\n' % bpr_mat.nnz)\n",
    "    file.write('Train matrix with %d stored elements\\n' % bpr_train.nnz)\n",
    "    file.write('Test matrix with %d stored elements\\n' % bpr_test.nnz)\n",
    "    file.write('Matrix initial with %d\\n' % initial_value)\n",
    "    file.write('Tru And Cong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 300\n",
    "n_rmd_items = 5\n",
    "score = predict_bpr(W, H, u)\n",
    "rmd_items = recommend_bpr(bpr_train, score, u, n_rmd_items)\n",
    "print(rmd_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tham khảo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner and Lars Schmidt-Thieme. BPR: Bayesian Personalized Ranking from Implicit Feedback. \n",
    "02. Weike Panand, Li Chen. GBPR: Group Preference Based Bayesian Personalized Ranking for One-Class Collaborative Filtering. Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence. https://www.aaai.org/ocs/index.php/IJCAI/IJCAI13/paper/viewFile/6316/7124\n",
    "03. Michael D. Ekstrand, Joseph A Konstan. Personalized Ranking (with Daniel Kluver). Matrix Factorization and Advanced Techniques - University of Minnesota. https://www.coursera.org/lecture/matrix-factorization/personalized-ranking-with-daniel-kluver-s3XJo\n",
    "04. Kim Falk. Practical Recommender Systems. Manning Publications.\n",
    "05. Ethen (MingYu) Liu. Bayesian Personalized Ranking. http://ethen8181.github.io/machine-learning/recsys/4_bpr.html\n",
    "06. Alfredo Láinez Rodrigo, Luke de Oliveira. Distributed Bayesian Personalized Ranking in Spark. https://stanford.edu/~rezab/classes/cme323/S16/projects_reports/rodrigo_oliveira.pdf"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
