{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc6ade13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load các thư viện cần thiết\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix, dok_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "np.random.seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ce3d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Similarity:\n",
    "    def __init__(self):\n",
    "        self.embedding = None\n",
    "        self.load_embedding()\n",
    "\n",
    "    def load_embedding(self):\n",
    "        with open(EMBEDDING_PATH, 'rb') as handle:\n",
    "            self.embedding = pickle.load(handle)\n",
    "\n",
    "    def similarity(self, item_i, item_j):\n",
    "        try:\n",
    "            x, y = self.embedding['N' + item_i], self.embedding['N' + item_j]\n",
    "            return cosine_similarity(x, y)\n",
    "        except Exception as e:\n",
    "            return -1\n",
    "\n",
    "def load_behaviors(path):\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        names = [\"id\", \"user_id\", \"history\", \"impressions\", \"number\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def write_file(df, path):\n",
    "    t_start = time()\n",
    "    print(\"Processing\", path)\n",
    "    with open(path, \"w\") as file:\n",
    "        for i, row in df.iterrows():\n",
    "            for new_id in str(row.history).split(' '):\n",
    "                if row.user_id[1:].isnumeric() and new_id[1:].isnumeric():\n",
    "                    file.write(row.user_id[1:] + \",\" + new_id[1:] + \"\\n\")\n",
    "\n",
    "    t_end = time()\n",
    "    print(\"Processed in: {:.2f} Seconds\".format(t_end - t_start))\n",
    "\n",
    "def write_data_file(train_path, output_train_path):\n",
    "    train_df = load_behaviors(train_path)\n",
    "\n",
    "    write_file(train_df, output_train_path)\n",
    "    \n",
    "def load_file(path):\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        header=None,\n",
    "        names=['user_id', 'item_id']\n",
    "    )\n",
    "    df.reindex(columns = ['user_id', 'item_id'])\n",
    "    return df.reset_index(drop = True)\n",
    "\n",
    "def load_data(train_path):\n",
    "    train_df = load_file(train_path)\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "def filter_df(df, user_min, item_min):\n",
    "    if df is None:\n",
    "        return\n",
    "\n",
    "    t_start = time()\n",
    "\n",
    "    user_counts = df.groupby(\"user_id\").size()\n",
    "    user_subset = np.in1d(\n",
    "        df.user_id, user_counts[user_counts >= item_min].index\n",
    "    )\n",
    "\n",
    "    filter_df = df[user_subset].reset_index(drop=True)\n",
    "\n",
    "    # find items with 10 or more users\n",
    "    item_counts = filter_df.groupby(\"item_id\").size()\n",
    "    item_subset = np.in1d(\n",
    "        filter_df.item_id, item_counts[item_counts >= user_min].index\n",
    "    )\n",
    "\n",
    "    filter_df = filter_df[item_subset].reset_index(drop=True)\n",
    "\n",
    "    user_counts = filter_df.groupby(\"user_id\").size()\n",
    "    user_subset = np.in1d(filter_df.user_id, user_counts[user_counts >= item_min].index)\n",
    "\n",
    "    filter_df = filter_df[user_subset].reset_index(drop=True)\n",
    "\n",
    "    t_end = time()\n",
    "\n",
    "#     assert (filter_df.groupby(\"user_id\").size() < 5).sum() == 0\n",
    "#     assert (filter_df.groupby(\"item_id\").size() < 5).sum() == 0\n",
    "\n",
    "    print(filter_df.nunique())\n",
    "    print(filter_df.shape)\n",
    "    print(\"{:.2f} Seconds\".format(t_end - t_start))\n",
    "\n",
    "    return filter_df\n",
    "\n",
    "def reset_df(df):\n",
    "    item_enc = LabelEncoder()\n",
    "    df['news_id'] = df[\"item_id\"]\n",
    "    df[\"item_id\"] = item_enc.fit_transform(df[\"item_id\"])\n",
    "\n",
    "    user_enc = LabelEncoder()\n",
    "    df[\"user_id\"] = user_enc.fit_transform(df[\"user_id\"])\n",
    "\n",
    "    assert df.user_id.min() == 0\n",
    "    assert df.item_id.min() == 0\n",
    "\n",
    "    return df\n",
    "\n",
    "def convert_to_bpr_mat(dataframe, threshold = 3):\n",
    "    tempdf = dataframe.copy()\n",
    "\n",
    "    # Vì tập dữ liệu này đánh index từ 1 nên chuyển sang kiểu category\n",
    "    # để tránh việc chúng ta có ma trận\n",
    "    tempdf['user_id'] = tempdf['user_id'].astype('category')\n",
    "    tempdf['item_id'] = tempdf['item_id'].astype('category')\n",
    "    tempdf['positive'] = 1\n",
    "\n",
    "    bpr_mat = csr_matrix((tempdf['positive'], (tempdf['user_id'].cat.codes, tempdf['item_id'].cat.codes)))\n",
    "    bpr_mat.eliminate_zeros()\n",
    "    del tempdf\n",
    "    return bpr_mat\n",
    "\n",
    "def split_to_train_test(bpr_mat, test_ratio = 0.2, verbose=True):\n",
    "    \"\"\"\n",
    "    Chia tập dữ liệu ra thành tập train & tập test\n",
    "\n",
    "    :param bpr_mat: ma trận bpr\n",
    "    :param test_ratio: float - tỉ lệ test set\n",
    "\n",
    "    :return train: ma trận bpr train\n",
    "    :return test: ma trận bpr test\n",
    "    \"\"\"\n",
    "    # Số lượng người dùng\n",
    "    n_users = bpr_mat.shape[0]\n",
    "    # Dùng ma trận thưa Dictionary Of Keys tối ưu hơn cho công đoạn này\n",
    "    train = bpr_mat.copy().todok()\n",
    "    test = dok_matrix(train.shape) # Lưu ý hiện tại test là ma trận 0\n",
    "\n",
    "    # với mỗi người dùng u\n",
    "    # chia số trường hợp nên khuyến nghị với tỉ lệ test_ratio đươc cho\n",
    "    # phần nào thuộc về test\n",
    "    for u in range(n_users):\n",
    "        split_index = bpr_mat[u].indices\n",
    "        # đếm số trường hợp nên khuyến nghị\n",
    "        count_positive = split_index.shape[0]\n",
    "        n_splits = max(min(math.ceil(test_ratio * count_positive), count_positive - 1), 1)\n",
    "        test_index = np.random.choice(split_index, size=n_splits, replace=False)\n",
    "        # Xem như dữ liệu chưa biết trong tập train\n",
    "        train[u, test_index] = 0\n",
    "        # Xem như dữ liệu nhìn thấy trong tập test\n",
    "        test[u, test_index] = 1\n",
    "\n",
    "    train, test = train.tocsr(), test.tocsr()\n",
    "\n",
    "    # Nếu cần in thông tin ra ngoài\n",
    "    if verbose:\n",
    "        print('BPR matrix with %d stored elements' % bpr_mat.nnz)\n",
    "        print('Train matrix with %d stored elements' % train.nnz)\n",
    "        print('Test matrix with %d stored elements' % test.nnz)\n",
    "    return train, test\n",
    "\n",
    "def predict_bpr(W, H, user=None):\n",
    "    \"\"\"\n",
    "    Hàm trả về X_hat\n",
    "\n",
    "    :param W: ma trận W từ MF\n",
    "    :param H: ma trận H từ MF\n",
    "    :param user: người dùng (nếu None mặt định trả về tất cả)\n",
    "\n",
    "    :return predict_scores: điểm dự đoán từ BPR MF\n",
    "    \"\"\"\n",
    "    if user is None:\n",
    "        return W @ H.T\n",
    "    else:\n",
    "        return W[user] @ H.T\n",
    "\n",
    "def recommend_bpr(bpr_matrix, predict_score, user, n_rmd_items=None):\n",
    "    \"\"\"\n",
    "    Dự đoán những sản phẩm mà người dùng muốn mua\n",
    "    Những sản phẩm nào đã thích rồi thì không trả về nữa\n",
    "    Trả về index theo bpr_matrix (đánh từ 0)\n",
    "\n",
    "    :param bpr_matrix: ma trận bpr hiện tại\n",
    "    :param predict_score: điểm dự đoán các item\n",
    "    :param user: số thứ tự người dùng của predict score\n",
    "    :param n_rmd_items: số lượng sản phẩm trả về, mặc định tất cả\n",
    "\n",
    "    :return rmd_items: danh sách các sản phẩm khuyến nghị\n",
    "    \"\"\"\n",
    "    # Số lượng sản phẩm\n",
    "    n_items = bpr_matrix.shape[1]\n",
    "    # những sản phẩm đã thích rồi\n",
    "    liked_items = bpr_matrix[user].indices\n",
    "    scores = predict_score.copy()\n",
    "\n",
    "    # index ban đầu khi chưa sắp xếp\n",
    "    sort_index = np.arange(0, n_items)\n",
    "\n",
    "    # Xóa các sản phẩm đã mua\n",
    "    sort_index = np.delete(sort_index, liked_items)\n",
    "    scores = np.delete(scores, liked_items)\n",
    "\n",
    "    # sắp xếp và trả về theo số thứ tự của score\n",
    "    arg_sort = np.argsort(-scores)\n",
    "\n",
    "    # dùng sort_index để lấy số thứ tự ban đầu\n",
    "    rmd_items = sort_index[arg_sort]\n",
    "\n",
    "    if len(rmd_items) >= n_rmd_items and n_rmd_items is not None:\n",
    "        rmd_items = rmd_items[: n_rmd_items]\n",
    "    return rmd_items\n",
    "\n",
    "def auc_score(predict_mat, bpr_mat):\n",
    "    \"\"\"\n",
    "    Tính Area under the ROC curve (AUC)\n",
    "    cho bài toán hệ khuyến nghị\n",
    "\n",
    "    :param predict_mat: ma trận dữ đoán bpr mf\n",
    "    :param bpr_mat: ma trận train hoặc test\n",
    "    :return auc: area under the roc curve\n",
    "    \"\"\"\n",
    "    auc = 0.0\n",
    "    n_users, n_items = bpr_mat.shape\n",
    "\n",
    "    # u và row tương ứng user và bp\n",
    "    for u in range(n_users):\n",
    "        y_pred = predict_mat[u]\n",
    "        y_true = np.zeros(n_items)\n",
    "        y_true[bpr_mat[u].indices] = 1\n",
    "        try:\n",
    "            auc += roc_auc_score(y_true, y_pred)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    auc /= n_users\n",
    "    return auc\n",
    "\n",
    "def learn_bpr_mf_sgd(bpr_mat, pos, neg, sim_model, mapper, W = None, H = None, alpha=0.01, lamb=0.01, k=12, n_iters=10000, initial_value=2, fine_and_reward = 0.3):\n",
    "    \"\"\"\n",
    "    Thuật toán học BPR MF SGD (một điểm dữ liệu duy nhất)\n",
    "\n",
    "    :param bpr_mat: ma trận bpr\n",
    "    :param alpha: hệ số learning rate\n",
    "    :param lamb: hệ số lambda của bình thường hóa regularization\n",
    "    :param k: số lượng latent factor trong bài toán MF\n",
    "    :param n_iters: số vòng lặp\n",
    "\n",
    "    :return W: ma trận W\n",
    "    :return H: ma trận H\n",
    "    \"\"\"\n",
    "    \n",
    "    n_users, n_items = bpr_mat.shape\n",
    "    # Khởi tạo ma trận W và ma trận H\n",
    "    if W is None:\n",
    "        W = np.empty(shape=(n_users, k))\n",
    "        W.fill(initial_value)\n",
    "    if H is None:\n",
    "        H = np.empty(shape=(n_items, k))\n",
    "        H.fill(initial_value)\n",
    "\n",
    "    # lặp\n",
    "    for _ in range(n_iters):\n",
    "        # ngẫu nghiên 3 bộ (u,i,j) từ D_S\n",
    "        u = np.random.randint(0, n_users)\n",
    "        if len(pos[u]) == 0:\n",
    "            continue\n",
    "        i = pos[u][np.random.randint(0, len(pos[u]))]\n",
    "        j = neg[u][np.random.randint(0, len(neg[u]))]\n",
    "\n",
    "        # Tính xuij\n",
    "        xui = (W[u] * H[i]).sum()\n",
    "        xuj = (W[u] * H[j]).sum()\n",
    "        xuij = np.tanh(xui - xuj)\n",
    "\n",
    "        similar = sim_model.similarity(mapper[i], mapper[j])\n",
    "        if similar != -1:\n",
    "            if similar > (1 - fine_and_reward):\n",
    "                xuij = xuij * (1 - similar)\n",
    "            elif similar < 0.5:\n",
    "                xuij = xuij * (1 + similar)            \n",
    "\n",
    "        # mũ tự nhiên e của xuij\n",
    "        exp_xuij = np.exp(xuij)\n",
    "\n",
    "        # sgd cho tham số Theta (W và H)\n",
    "        W[u] = W[u] + alpha * ( exp_xuij / (1+exp_xuij) * (H[i] - H[j]) + lamb * W[u])\n",
    "        H[i] = H[i] + alpha * ( exp_xuij / (1+exp_xuij) * W[u] + lamb * H[i])\n",
    "        H[j] = H[j] + alpha * ( exp_xuij / (1+exp_xuij) * (-W[u]) + lamb * H[j])\n",
    "    return W, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bfdb224",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './bert/behaviors.csv'\n",
    "EMBEDDING_PATH = './bert/news_content_bert_features.pickle'\n",
    "\n",
    "output_train_path = './datafile/bert.csv'\n",
    "\n",
    "result_train_file = 'bert'\n",
    "\n",
    "test_ratio = 0.4\n",
    "\n",
    "alpha=0.001\n",
    "lamb=0.02\n",
    "k=60\n",
    "training_per_interact = 10\n",
    "initial_value = 0.5\n",
    "fine_and_reward = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c866c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user min: 81\n",
      "item min: 166\n",
      "user_id    8467\n",
      "item_id    8396\n",
      "dtype: int64\n",
      "(4444252, 2)\n",
      "1.14 Seconds\n",
      "(8467, 8396)\n"
     ]
    }
   ],
   "source": [
    "train_df = load_data(output_train_path)\n",
    "\n",
    "user_min = int(train_df.groupby(\"user_id\").size().mean())\n",
    "item_min = int(train_df.groupby(\"item_id\").size().mean())\n",
    "\n",
    "print('user min: %i\\nitem min: %i' % (user_min, item_min))\n",
    "\n",
    "sim_model = Similarity()\n",
    "\n",
    "# Filter by user_min and item_min\n",
    "filtered_df = reset_df(filter_df(train_df, user_min, item_min))\n",
    "bpr_mat = convert_to_bpr_mat(filtered_df)\n",
    "print(bpr_mat.shape)\n",
    "\n",
    "# Calculate mapper\n",
    "mapper = pd.Series(filtered_df[\"news_id\"].values,index=filtered_df['item_id']).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc33de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPR matrix with 574867 stored elements\n",
      "Train matrix with 341482 stored elements\n",
      "Test matrix with 233385 stored elements\n",
      "n iters: 3414820\n",
      "AUC of train: 0.803100\n",
      "AUC of test : 0.793745\n",
      "BPR matrix with 574867 stored elements\n",
      "Train matrix with 341482 stored elements\n",
      "Test matrix with 233385 stored elements\n",
      "n iters: 3414820\n",
      "AUC of train: 0.802578\n",
      "AUC of test : 0.794192\n",
      "BPR matrix with 574867 stored elements\n",
      "Train matrix with 341482 stored elements\n",
      "Test matrix with 233385 stored elements\n",
      "n iters: 3414820\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    # Split to train and test\n",
    "    bpr_train, bpr_test = split_to_train_test(bpr_mat, test_ratio=test_ratio, verbose=True)\n",
    "\n",
    "    n_iters = training_per_interact * bpr_train.nnz\n",
    "    print('n iters: %i' % n_iters)\n",
    "\n",
    "    # Prepare to train\n",
    "    W, H = None, None\n",
    "    pos = np.split(bpr_train.indices, bpr_train.indptr)[1:-1]\n",
    "    neg = [np.setdiff1d(np.arange(0, bpr_train.shape[1], 1), e) for e in pos]\n",
    "\n",
    "    W, H = learn_bpr_mf_sgd(\n",
    "        bpr_train,\n",
    "        pos,\n",
    "        neg,\n",
    "        sim_model,\n",
    "        mapper,\n",
    "        W = W,\n",
    "        H = H,\n",
    "        alpha=alpha,\n",
    "        lamb=lamb,\n",
    "        k=k,\n",
    "        n_iters=n_iters,\n",
    "        initial_value = initial_value,\n",
    "        fine_and_reward = fine_and_reward\n",
    "    )\n",
    "\n",
    "    pred = predict_bpr(W, H)\n",
    "\n",
    "    train_score = auc_score(pred, bpr_train)\n",
    "    test_score = auc_score(pred, bpr_test)\n",
    "    print('AUC of train: %f' % train_score)\n",
    "    print('AUC of test : %f' % test_score)\n",
    "    \n",
    "    \n",
    "    output_folder = os.path.join('./result', datetime.now().strftime(\"%d-%m-%Y %H-%M\"))\n",
    "\n",
    "    pathlib.Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    np.save(os.path.join(output_folder, result_train_file + '_W.npy'), W)\n",
    "    np.save(os.path.join(output_folder, result_train_file + '_H.npy'), H)\n",
    "\n",
    "    with open(os.path.join(output_folder, result_train_file + '.txt'), 'w') as file:\n",
    "        file.write(\"Parameters:\\n\\n\")\n",
    "        file.write('user min: %i' % user_min + \"\\n\")\n",
    "        file.write('item min: %i' % item_min + \"\\n\")\n",
    "        file.write('test ratio: %f' % test_ratio + \"\\n\")\n",
    "        file.write('alpha: %f' % alpha + \"\\n\")\n",
    "        file.write('lambda: %f' % lamb + \"\\n\")\n",
    "        file.write('k: %i' % k + \"\\n\")\n",
    "        file.write('n iters: %i' % n_iters + \"\\n\")\n",
    "        file.write('AUC-Train: %f' % train_score + \"\\n\")\n",
    "        file.write('AUC-Test: %f' % test_score + \"\\n\")\n",
    "        file.write(\"---------------------\\n\")\n",
    "        file.write('Total users: %i \\n' % train_df.nunique()[0])\n",
    "        file.write('Total items: %i \\n' % train_df.nunique()[1])\n",
    "        file.write('Total interacts: %i \\n' % train_df.shape[0])\n",
    "        file.write('No training users: %i \\n' % filtered_df.nunique()[0])\n",
    "        file.write('No training items: %i \\n' % filtered_df.nunique()[1])\n",
    "        file.write('BPR matrix with %d stored elements\\n' % bpr_mat.nnz)\n",
    "        file.write('Train matrix with %d stored elements\\n' % bpr_train.nnz)\n",
    "        file.write('Test matrix with %d stored elements\\n' % bpr_test.nnz)\n",
    "        file.write('Matrix initial with %d\\n' % initial_value)\n",
    "        file.write('Fine and Reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54277d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
